{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4: Quantization Theory\n",
    "\n",
    "In this lab, you will perform Linear Quantization.\n",
    "\n",
    "#### Libraries to install\n",
    "- If you are running this notebook on your local machine, you can install the following:\n",
    "\n",
    "```Python\n",
    "!pip install transformers==4.35.0\n",
    "!pip install quanto==0.0.11\n",
    "!pip install torch==2.1.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5-FLAN\n",
    "- Please note that due to hardware memory constraints, and in order to offer this course for free to everyone, the code you'll run here is for the T5-FLAN model instead of the EleutherAI AI Pythia model.  \n",
    "- Thank you for your understanding! ðŸ¤—\n",
    "\n",
    "For the T5-FLAN model, here is one more library to install if you are running locally:\n",
    "```Python\n",
    "!pip install sentencepiece==0.2.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/flan-t5-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(pretrained_model_name_or_path=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(pretrained_model_name_or_path=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> annie scott</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaushik/miniconda3/envs/py3_quantization_fundamentals_course/lib/python3.9/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Hello, my name is \"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the original model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'': 307844608.0,\n",
       "             'shared': 65798144.0,\n",
       "             'shared.weight': 65798144.0,\n",
       "             'encoder': 75533056.0,\n",
       "             'encoder.block': 75531008.0,\n",
       "             'encoder.block.0': 9442048.0,\n",
       "             'encoder.block.0.layer': 9442048.0,\n",
       "             'encoder.block.0.layer.0': 3148544.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention': 3146496.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.q': 786432.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.q.weight': 786432.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.k': 786432.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.k.weight': 786432.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.v': 786432.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.v.weight': 786432.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.o': 786432.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.o.weight': 786432.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.relative_attention_bias': 768.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight': 768.0,\n",
       "             'encoder.block.0.layer.0.layer_norm': 2048.0,\n",
       "             'encoder.block.0.layer.0.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.0.layer.1': 6293504.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense': 6291456.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wi_0': 2097152.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wi_0.weight': 2097152.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wi_1': 2097152.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wi_1.weight': 2097152.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wo': 2097152.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wo.weight': 2097152.0,\n",
       "             'encoder.block.0.layer.1.layer_norm': 2048.0,\n",
       "             'encoder.block.0.layer.1.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.1': 9441280.0,\n",
       "             'encoder.block.1.layer': 9441280.0,\n",
       "             'encoder.block.1.layer.0': 3147776.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention': 3145728.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.q': 786432.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.q.weight': 786432.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.k': 786432.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.k.weight': 786432.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.v': 786432.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.v.weight': 786432.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.o': 786432.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.o.weight': 786432.0,\n",
       "             'encoder.block.1.layer.0.layer_norm': 2048.0,\n",
       "             'encoder.block.1.layer.0.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.1.layer.1': 6293504.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense': 6291456.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wi_0': 2097152.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wi_0.weight': 2097152.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wi_1': 2097152.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wi_1.weight': 2097152.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wo': 2097152.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wo.weight': 2097152.0,\n",
       "             'encoder.block.1.layer.1.layer_norm': 2048.0,\n",
       "             'encoder.block.1.layer.1.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.2': 9441280.0,\n",
       "             'encoder.block.2.layer': 9441280.0,\n",
       "             'encoder.block.2.layer.0': 3147776.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention': 3145728.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.q': 786432.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.q.weight': 786432.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.k': 786432.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.k.weight': 786432.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.v': 786432.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.v.weight': 786432.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.o': 786432.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.o.weight': 786432.0,\n",
       "             'encoder.block.2.layer.0.layer_norm': 2048.0,\n",
       "             'encoder.block.2.layer.0.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.2.layer.1': 6293504.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense': 6291456.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wi_0': 2097152.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wi_0.weight': 2097152.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wi_1': 2097152.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wi_1.weight': 2097152.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wo': 2097152.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wo.weight': 2097152.0,\n",
       "             'encoder.block.2.layer.1.layer_norm': 2048.0,\n",
       "             'encoder.block.2.layer.1.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.3': 9441280.0,\n",
       "             'encoder.block.3.layer': 9441280.0,\n",
       "             'encoder.block.3.layer.0': 3147776.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention': 3145728.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.q': 786432.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.q.weight': 786432.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.k': 786432.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.k.weight': 786432.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.v': 786432.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.v.weight': 786432.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.o': 786432.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.o.weight': 786432.0,\n",
       "             'encoder.block.3.layer.0.layer_norm': 2048.0,\n",
       "             'encoder.block.3.layer.0.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.3.layer.1': 6293504.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense': 6291456.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wi_0': 2097152.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wi_0.weight': 2097152.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wi_1': 2097152.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wi_1.weight': 2097152.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wo': 2097152.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wo.weight': 2097152.0,\n",
       "             'encoder.block.3.layer.1.layer_norm': 2048.0,\n",
       "             'encoder.block.3.layer.1.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.4': 9441280.0,\n",
       "             'encoder.block.4.layer': 9441280.0,\n",
       "             'encoder.block.4.layer.0': 3147776.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention': 3145728.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.q': 786432.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.q.weight': 786432.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.k': 786432.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.k.weight': 786432.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.v': 786432.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.v.weight': 786432.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.o': 786432.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.o.weight': 786432.0,\n",
       "             'encoder.block.4.layer.0.layer_norm': 2048.0,\n",
       "             'encoder.block.4.layer.0.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.4.layer.1': 6293504.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense': 6291456.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wi_0': 2097152.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wi_0.weight': 2097152.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wi_1': 2097152.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wi_1.weight': 2097152.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wo': 2097152.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wo.weight': 2097152.0,\n",
       "             'encoder.block.4.layer.1.layer_norm': 2048.0,\n",
       "             'encoder.block.4.layer.1.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.5': 9441280.0,\n",
       "             'encoder.block.5.layer': 9441280.0,\n",
       "             'encoder.block.5.layer.0': 3147776.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention': 3145728.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.q': 786432.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.q.weight': 786432.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.k': 786432.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.k.weight': 786432.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.v': 786432.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.v.weight': 786432.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.o': 786432.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.o.weight': 786432.0,\n",
       "             'encoder.block.5.layer.0.layer_norm': 2048.0,\n",
       "             'encoder.block.5.layer.0.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.5.layer.1': 6293504.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense': 6291456.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wi_0': 2097152.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wi_0.weight': 2097152.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wi_1': 2097152.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wi_1.weight': 2097152.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wo': 2097152.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wo.weight': 2097152.0,\n",
       "             'encoder.block.5.layer.1.layer_norm': 2048.0,\n",
       "             'encoder.block.5.layer.1.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.6': 9441280.0,\n",
       "             'encoder.block.6.layer': 9441280.0,\n",
       "             'encoder.block.6.layer.0': 3147776.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention': 3145728.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.q': 786432.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.q.weight': 786432.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.k': 786432.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.k.weight': 786432.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.v': 786432.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.v.weight': 786432.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.o': 786432.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.o.weight': 786432.0,\n",
       "             'encoder.block.6.layer.0.layer_norm': 2048.0,\n",
       "             'encoder.block.6.layer.0.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.6.layer.1': 6293504.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense': 6291456.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wi_0': 2097152.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wi_0.weight': 2097152.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wi_1': 2097152.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wi_1.weight': 2097152.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wo': 2097152.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wo.weight': 2097152.0,\n",
       "             'encoder.block.6.layer.1.layer_norm': 2048.0,\n",
       "             'encoder.block.6.layer.1.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.7': 9441280.0,\n",
       "             'encoder.block.7.layer': 9441280.0,\n",
       "             'encoder.block.7.layer.0': 3147776.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention': 3145728.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.q': 786432.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.q.weight': 786432.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.k': 786432.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.k.weight': 786432.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.v': 786432.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.v.weight': 786432.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.o': 786432.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.o.weight': 786432.0,\n",
       "             'encoder.block.7.layer.0.layer_norm': 2048.0,\n",
       "             'encoder.block.7.layer.0.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.7.layer.1': 6293504.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense': 6291456.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wi_0': 2097152.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wi_0.weight': 2097152.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wi_1': 2097152.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wi_1.weight': 2097152.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wo': 2097152.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wo.weight': 2097152.0,\n",
       "             'encoder.block.7.layer.1.layer_norm': 2048.0,\n",
       "             'encoder.block.7.layer.1.layer_norm.weight': 2048.0,\n",
       "             'encoder.final_layer_norm': 2048.0,\n",
       "             'encoder.final_layer_norm.weight': 2048.0,\n",
       "             'decoder': 100715264.0,\n",
       "             'decoder.block': 100713216.0,\n",
       "             'decoder.block.0': 12589824.0,\n",
       "             'decoder.block.0.layer': 12589824.0,\n",
       "             'decoder.block.0.layer.0': 3148544.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention': 3146496.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.q': 786432.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.q.weight': 786432.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.k': 786432.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.k.weight': 786432.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.v': 786432.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.v.weight': 786432.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.o': 786432.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.o.weight': 786432.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.relative_attention_bias': 768.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight': 768.0,\n",
       "             'decoder.block.0.layer.0.layer_norm': 2048.0,\n",
       "             'decoder.block.0.layer.0.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.0.layer.1': 3147776.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention': 3145728.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.q': 786432.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.q.weight': 786432.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.k': 786432.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.k.weight': 786432.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.v': 786432.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.v.weight': 786432.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.o': 786432.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.o.weight': 786432.0,\n",
       "             'decoder.block.0.layer.1.layer_norm': 2048.0,\n",
       "             'decoder.block.0.layer.1.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.0.layer.2': 6293504.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense': 6291456.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wi_0': 2097152.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wi_0.weight': 2097152.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wi_1': 2097152.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wi_1.weight': 2097152.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wo': 2097152.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wo.weight': 2097152.0,\n",
       "             'decoder.block.0.layer.2.layer_norm': 2048.0,\n",
       "             'decoder.block.0.layer.2.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.1': 12589056.0,\n",
       "             'decoder.block.1.layer': 12589056.0,\n",
       "             'decoder.block.1.layer.0': 3147776.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention': 3145728.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.q': 786432.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.q.weight': 786432.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.k': 786432.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.k.weight': 786432.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.v': 786432.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.v.weight': 786432.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.o': 786432.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.o.weight': 786432.0,\n",
       "             'decoder.block.1.layer.0.layer_norm': 2048.0,\n",
       "             'decoder.block.1.layer.0.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.1.layer.1': 3147776.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention': 3145728.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.q': 786432.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.q.weight': 786432.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.k': 786432.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.k.weight': 786432.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.v': 786432.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.v.weight': 786432.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.o': 786432.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.o.weight': 786432.0,\n",
       "             'decoder.block.1.layer.1.layer_norm': 2048.0,\n",
       "             'decoder.block.1.layer.1.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.1.layer.2': 6293504.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense': 6291456.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wi_0': 2097152.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wi_0.weight': 2097152.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wi_1': 2097152.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wi_1.weight': 2097152.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wo': 2097152.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wo.weight': 2097152.0,\n",
       "             'decoder.block.1.layer.2.layer_norm': 2048.0,\n",
       "             'decoder.block.1.layer.2.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.2': 12589056.0,\n",
       "             'decoder.block.2.layer': 12589056.0,\n",
       "             'decoder.block.2.layer.0': 3147776.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention': 3145728.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.q': 786432.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.q.weight': 786432.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.k': 786432.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.k.weight': 786432.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.v': 786432.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.v.weight': 786432.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.o': 786432.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.o.weight': 786432.0,\n",
       "             'decoder.block.2.layer.0.layer_norm': 2048.0,\n",
       "             'decoder.block.2.layer.0.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.2.layer.1': 3147776.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention': 3145728.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.q': 786432.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.q.weight': 786432.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.k': 786432.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.k.weight': 786432.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.v': 786432.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.v.weight': 786432.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.o': 786432.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.o.weight': 786432.0,\n",
       "             'decoder.block.2.layer.1.layer_norm': 2048.0,\n",
       "             'decoder.block.2.layer.1.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.2.layer.2': 6293504.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense': 6291456.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wi_0': 2097152.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wi_0.weight': 2097152.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wi_1': 2097152.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wi_1.weight': 2097152.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wo': 2097152.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wo.weight': 2097152.0,\n",
       "             'decoder.block.2.layer.2.layer_norm': 2048.0,\n",
       "             'decoder.block.2.layer.2.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.3': 12589056.0,\n",
       "             'decoder.block.3.layer': 12589056.0,\n",
       "             'decoder.block.3.layer.0': 3147776.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention': 3145728.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.q': 786432.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.q.weight': 786432.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.k': 786432.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.k.weight': 786432.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.v': 786432.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.v.weight': 786432.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.o': 786432.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.o.weight': 786432.0,\n",
       "             'decoder.block.3.layer.0.layer_norm': 2048.0,\n",
       "             'decoder.block.3.layer.0.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.3.layer.1': 3147776.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention': 3145728.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.q': 786432.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.q.weight': 786432.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.k': 786432.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.k.weight': 786432.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.v': 786432.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.v.weight': 786432.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.o': 786432.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.o.weight': 786432.0,\n",
       "             'decoder.block.3.layer.1.layer_norm': 2048.0,\n",
       "             'decoder.block.3.layer.1.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.3.layer.2': 6293504.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense': 6291456.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wi_0': 2097152.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wi_0.weight': 2097152.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wi_1': 2097152.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wi_1.weight': 2097152.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wo': 2097152.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wo.weight': 2097152.0,\n",
       "             'decoder.block.3.layer.2.layer_norm': 2048.0,\n",
       "             'decoder.block.3.layer.2.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.4': 12589056.0,\n",
       "             'decoder.block.4.layer': 12589056.0,\n",
       "             'decoder.block.4.layer.0': 3147776.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention': 3145728.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.q': 786432.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.q.weight': 786432.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.k': 786432.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.k.weight': 786432.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.v': 786432.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.v.weight': 786432.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.o': 786432.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.o.weight': 786432.0,\n",
       "             'decoder.block.4.layer.0.layer_norm': 2048.0,\n",
       "             'decoder.block.4.layer.0.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.4.layer.1': 3147776.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention': 3145728.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.q': 786432.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.q.weight': 786432.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.k': 786432.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.k.weight': 786432.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.v': 786432.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.v.weight': 786432.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.o': 786432.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.o.weight': 786432.0,\n",
       "             'decoder.block.4.layer.1.layer_norm': 2048.0,\n",
       "             'decoder.block.4.layer.1.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.4.layer.2': 6293504.0,\n",
       "             'decoder.block.4.layer.2.DenseReluDense': 6291456.0,\n",
       "             'decoder.block.4.layer.2.DenseReluDense.wi_0': 2097152.0,\n",
       "             'decoder.block.4.layer.2.DenseReluDense.wi_0.weight': 2097152.0,\n",
       "             'decoder.block.4.layer.2.DenseReluDense.wi_1': 2097152.0,\n",
       "             'decoder.block.4.layer.2.DenseReluDense.wi_1.weight': 2097152.0,\n",
       "             'decoder.block.4.layer.2.DenseReluDense.wo': 2097152.0,\n",
       "             'decoder.block.4.layer.2.DenseReluDense.wo.weight': 2097152.0,\n",
       "             'decoder.block.4.layer.2.layer_norm': 2048.0,\n",
       "             'decoder.block.4.layer.2.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.5': 12589056.0,\n",
       "             'decoder.block.5.layer': 12589056.0,\n",
       "             'decoder.block.5.layer.0': 3147776.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention': 3145728.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.q': 786432.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.q.weight': 786432.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.k': 786432.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.k.weight': 786432.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.v': 786432.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.v.weight': 786432.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.o': 786432.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.o.weight': 786432.0,\n",
       "             'decoder.block.5.layer.0.layer_norm': 2048.0,\n",
       "             'decoder.block.5.layer.0.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.5.layer.1': 3147776.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention': 3145728.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.q': 786432.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.q.weight': 786432.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.k': 786432.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.k.weight': 786432.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.v': 786432.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.v.weight': 786432.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.o': 786432.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.o.weight': 786432.0,\n",
       "             'decoder.block.5.layer.1.layer_norm': 2048.0,\n",
       "             'decoder.block.5.layer.1.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.5.layer.2': 6293504.0,\n",
       "             'decoder.block.5.layer.2.DenseReluDense': 6291456.0,\n",
       "             'decoder.block.5.layer.2.DenseReluDense.wi_0': 2097152.0,\n",
       "             'decoder.block.5.layer.2.DenseReluDense.wi_0.weight': 2097152.0,\n",
       "             'decoder.block.5.layer.2.DenseReluDense.wi_1': 2097152.0,\n",
       "             'decoder.block.5.layer.2.DenseReluDense.wi_1.weight': 2097152.0,\n",
       "             'decoder.block.5.layer.2.DenseReluDense.wo': 2097152.0,\n",
       "             'decoder.block.5.layer.2.DenseReluDense.wo.weight': 2097152.0,\n",
       "             'decoder.block.5.layer.2.layer_norm': 2048.0,\n",
       "             'decoder.block.5.layer.2.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.6': 12589056.0,\n",
       "             'decoder.block.6.layer': 12589056.0,\n",
       "             'decoder.block.6.layer.0': 3147776.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention': 3145728.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.q': 786432.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.q.weight': 786432.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.k': 786432.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.k.weight': 786432.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.v': 786432.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.v.weight': 786432.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.o': 786432.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.o.weight': 786432.0,\n",
       "             'decoder.block.6.layer.0.layer_norm': 2048.0,\n",
       "             'decoder.block.6.layer.0.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.6.layer.1': 3147776.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention': 3145728.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.q': 786432.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.q.weight': 786432.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.k': 786432.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.k.weight': 786432.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.v': 786432.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.v.weight': 786432.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.o': 786432.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.o.weight': 786432.0,\n",
       "             'decoder.block.6.layer.1.layer_norm': 2048.0,\n",
       "             'decoder.block.6.layer.1.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.6.layer.2': 6293504.0,\n",
       "             'decoder.block.6.layer.2.DenseReluDense': 6291456.0,\n",
       "             'decoder.block.6.layer.2.DenseReluDense.wi_0': 2097152.0,\n",
       "             'decoder.block.6.layer.2.DenseReluDense.wi_0.weight': 2097152.0,\n",
       "             'decoder.block.6.layer.2.DenseReluDense.wi_1': 2097152.0,\n",
       "             'decoder.block.6.layer.2.DenseReluDense.wi_1.weight': 2097152.0,\n",
       "             'decoder.block.6.layer.2.DenseReluDense.wo': 2097152.0,\n",
       "             'decoder.block.6.layer.2.DenseReluDense.wo.weight': 2097152.0,\n",
       "             'decoder.block.6.layer.2.layer_norm': 2048.0,\n",
       "             'decoder.block.6.layer.2.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.7': 12589056.0,\n",
       "             'decoder.block.7.layer': 12589056.0,\n",
       "             'decoder.block.7.layer.0': 3147776.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention': 3145728.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.q': 786432.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.q.weight': 786432.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.k': 786432.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.k.weight': 786432.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.v': 786432.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.v.weight': 786432.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.o': 786432.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.o.weight': 786432.0,\n",
       "             'decoder.block.7.layer.0.layer_norm': 2048.0,\n",
       "             'decoder.block.7.layer.0.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.7.layer.1': 3147776.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention': 3145728.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.q': 786432.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.q.weight': 786432.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.k': 786432.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.k.weight': 786432.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.v': 786432.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.v.weight': 786432.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.o': 786432.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.o.weight': 786432.0,\n",
       "             'decoder.block.7.layer.1.layer_norm': 2048.0,\n",
       "             'decoder.block.7.layer.1.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.7.layer.2': 6293504.0,\n",
       "             'decoder.block.7.layer.2.DenseReluDense': 6291456.0,\n",
       "             'decoder.block.7.layer.2.DenseReluDense.wi_0': 2097152.0,\n",
       "             'decoder.block.7.layer.2.DenseReluDense.wi_0.weight': 2097152.0,\n",
       "             'decoder.block.7.layer.2.DenseReluDense.wi_1': 2097152.0,\n",
       "             'decoder.block.7.layer.2.DenseReluDense.wi_1.weight': 2097152.0,\n",
       "             'decoder.block.7.layer.2.DenseReluDense.wo': 2097152.0,\n",
       "             'decoder.block.7.layer.2.DenseReluDense.wo.weight': 2097152.0,\n",
       "             'decoder.block.7.layer.2.layer_norm': 2048.0,\n",
       "             'decoder.block.7.layer.2.layer_norm.weight': 2048.0,\n",
       "             'decoder.final_layer_norm': 2048.0,\n",
       "             'decoder.final_layer_norm.weight': 2048.0,\n",
       "             'lm_head': 65798144.0,\n",
       "             'lm_head.weight': 65798144.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper import compute_model_sizes\n",
    "\n",
    "module_sizes = compute_model_sizes(model=model)\n",
    "module_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model size is 0.307844608 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"The model size is {module_sizes[''] * 1e-9} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantize the model (8-bit precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quanto import quantize, freeze\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize(model=model, weights=torch.int8, activations=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5ForConditionalGeneration(\n",
      "  (shared): Embedding(32128, 512)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): QLinear(in_features=512, out_features=384, bias=False)\n",
      "              (k): QLinear(in_features=512, out_features=384, bias=False)\n",
      "              (v): QLinear(in_features=512, out_features=384, bias=False)\n",
      "              (o): QLinear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): QLinear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): QLinear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): QLinear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): QLinear(in_features=512, out_features=384, bias=False)\n",
      "              (k): QLinear(in_features=512, out_features=384, bias=False)\n",
      "              (v): QLinear(in_features=512, out_features=384, bias=False)\n",
      "              (o): QLinear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): QLinear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): QLinear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): QLinear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): QLinear(in_features=512, out_features=384, bias=False)\n",
      "              (k): QLinear(in_features=512, out_features=384, bias=False)\n",
      "              (v): QLinear(in_features=512, out_features=384, bias=False)\n",
      "              (o): QLinear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): QLinear(in_features=512, out_features=384, bias=False)\n",
      "              (k): QLinear(in_features=512, out_features=384, bias=False)\n",
      "              (v): QLinear(in_features=512, out_features=384, bias=False)\n",
      "              (o): QLinear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): QLinear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): QLinear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): QLinear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): QLinear(in_features=512, out_features=384, bias=False)\n",
      "              (k): QLinear(in_features=512, out_features=384, bias=False)\n",
      "              (v): QLinear(in_features=512, out_features=384, bias=False)\n",
      "              (o): QLinear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): QLinear(in_features=512, out_features=384, bias=False)\n",
      "              (k): QLinear(in_features=512, out_features=384, bias=False)\n",
      "              (v): QLinear(in_features=512, out_features=384, bias=False)\n",
      "              (o): QLinear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): QLinear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): QLinear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): QLinear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): QLinear(in_features=512, out_features=32128, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze the model\n",
    "- This step takes a bit of memory, and so for the Pythia model that is shown in the lecture video, it will not run in the classroom.\n",
    "- This will work fine with the smaller T5-Flan model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'': 126828680.0,\n",
       "             'shared': 65798144.0,\n",
       "             'shared.weight': 65798144.0,\n",
       "             'encoder': 19045568.0,\n",
       "             'encoder.block': 19043520.0,\n",
       "             'encoder.block.0': 2381112.0,\n",
       "             'encoder.block.0.layer': 2381112.0,\n",
       "             'encoder.block.0.layer.0': 795936.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention': 793888.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.q': 198152.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.q.weight': 198144.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.q.weight._data': 196608.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.q.weight._scale': 1536.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.k': 198152.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.k.weight': 198144.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.k.weight._data': 196608.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.k.weight._scale': 1536.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.v': 198152.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.v.weight': 198144.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.v.weight._data': 196608.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.v.weight._scale': 1536.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.o': 198664.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.o.weight': 198656.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.o.weight._data': 196608.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.o.weight._scale': 2048.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.relative_attention_bias': 768.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight': 768.0,\n",
       "             'encoder.block.0.layer.0.layer_norm': 2048.0,\n",
       "             'encoder.block.0.layer.0.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.0.layer.1': 1585176.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense': 1583128.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wi_0': 528392.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wi_0.weight': 528384.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wi_0.weight._data': 524288.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wi_0.weight._scale': 4096.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wi_1': 528392.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wi_1.weight': 528384.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wi_1.weight._data': 524288.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wi_1.weight._scale': 4096.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wo': 526344.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wo.weight': 526336.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wo.weight._data': 524288.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wo.weight._scale': 2048.0,\n",
       "             'encoder.block.0.layer.1.layer_norm': 2048.0,\n",
       "             'encoder.block.0.layer.1.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.1': 2380344.0,\n",
       "             'encoder.block.1.layer': 2380344.0,\n",
       "             'encoder.block.1.layer.0': 795168.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention': 793120.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.q': 198152.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.q.weight': 198144.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.q.weight._data': 196608.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.q.weight._scale': 1536.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.k': 198152.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.k.weight': 198144.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.k.weight._data': 196608.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.k.weight._scale': 1536.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.v': 198152.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.v.weight': 198144.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.v.weight._data': 196608.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.v.weight._scale': 1536.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.o': 198664.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.o.weight': 198656.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.o.weight._data': 196608.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.o.weight._scale': 2048.0,\n",
       "             'encoder.block.1.layer.0.layer_norm': 2048.0,\n",
       "             'encoder.block.1.layer.0.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.1.layer.1': 1585176.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense': 1583128.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wi_0': 528392.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wi_0.weight': 528384.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wi_0.weight._data': 524288.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wi_0.weight._scale': 4096.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wi_1': 528392.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wi_1.weight': 528384.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wi_1.weight._data': 524288.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wi_1.weight._scale': 4096.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wo': 526344.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wo.weight': 526336.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wo.weight._data': 524288.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wo.weight._scale': 2048.0,\n",
       "             'encoder.block.1.layer.1.layer_norm': 2048.0,\n",
       "             'encoder.block.1.layer.1.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.2': 2380344.0,\n",
       "             'encoder.block.2.layer': 2380344.0,\n",
       "             'encoder.block.2.layer.0': 795168.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention': 793120.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.q': 198152.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.q.weight': 198144.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.q.weight._data': 196608.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.q.weight._scale': 1536.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.k': 198152.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.k.weight': 198144.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.k.weight._data': 196608.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.k.weight._scale': 1536.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.v': 198152.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.v.weight': 198144.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.v.weight._data': 196608.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.v.weight._scale': 1536.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.o': 198664.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.o.weight': 198656.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.o.weight._data': 196608.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.o.weight._scale': 2048.0,\n",
       "             'encoder.block.2.layer.0.layer_norm': 2048.0,\n",
       "             'encoder.block.2.layer.0.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.2.layer.1': 1585176.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense': 1583128.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wi_0': 528392.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wi_0.weight': 528384.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wi_0.weight._data': 524288.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wi_0.weight._scale': 4096.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wi_1': 528392.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wi_1.weight': 528384.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wi_1.weight._data': 524288.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wi_1.weight._scale': 4096.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wo': 526344.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wo.weight': 526336.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wo.weight._data': 524288.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wo.weight._scale': 2048.0,\n",
       "             'encoder.block.2.layer.1.layer_norm': 2048.0,\n",
       "             'encoder.block.2.layer.1.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.3': 2380344.0,\n",
       "             'encoder.block.3.layer': 2380344.0,\n",
       "             'encoder.block.3.layer.0': 795168.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention': 793120.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.q': 198152.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.q.weight': 198144.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.q.weight._data': 196608.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.q.weight._scale': 1536.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.k': 198152.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.k.weight': 198144.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.k.weight._data': 196608.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.k.weight._scale': 1536.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.v': 198152.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.v.weight': 198144.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.v.weight._data': 196608.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.v.weight._scale': 1536.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.o': 198664.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.o.weight': 198656.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.o.weight._data': 196608.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.o.weight._scale': 2048.0,\n",
       "             'encoder.block.3.layer.0.layer_norm': 2048.0,\n",
       "             'encoder.block.3.layer.0.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.3.layer.1': 1585176.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense': 1583128.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wi_0': 528392.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wi_0.weight': 528384.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wi_0.weight._data': 524288.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wi_0.weight._scale': 4096.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wi_1': 528392.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wi_1.weight': 528384.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wi_1.weight._data': 524288.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wi_1.weight._scale': 4096.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wo': 526344.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wo.weight': 526336.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wo.weight._data': 524288.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wo.weight._scale': 2048.0,\n",
       "             'encoder.block.3.layer.1.layer_norm': 2048.0,\n",
       "             'encoder.block.3.layer.1.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.4': 2380344.0,\n",
       "             'encoder.block.4.layer': 2380344.0,\n",
       "             'encoder.block.4.layer.0': 795168.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention': 793120.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.q': 198152.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.q.weight': 198144.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.q.weight._data': 196608.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.q.weight._scale': 1536.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.k': 198152.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.k.weight': 198144.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.k.weight._data': 196608.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.k.weight._scale': 1536.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.v': 198152.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.v.weight': 198144.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.v.weight._data': 196608.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.v.weight._scale': 1536.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.o': 198664.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.o.weight': 198656.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.o.weight._data': 196608.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.o.weight._scale': 2048.0,\n",
       "             'encoder.block.4.layer.0.layer_norm': 2048.0,\n",
       "             'encoder.block.4.layer.0.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.4.layer.1': 1585176.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense': 1583128.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wi_0': 528392.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wi_0.weight': 528384.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wi_0.weight._data': 524288.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wi_0.weight._scale': 4096.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wi_1': 528392.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wi_1.weight': 528384.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wi_1.weight._data': 524288.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wi_1.weight._scale': 4096.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wo': 526344.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wo.weight': 526336.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wo.weight._data': 524288.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wo.weight._scale': 2048.0,\n",
       "             'encoder.block.4.layer.1.layer_norm': 2048.0,\n",
       "             'encoder.block.4.layer.1.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.5': 2380344.0,\n",
       "             'encoder.block.5.layer': 2380344.0,\n",
       "             'encoder.block.5.layer.0': 795168.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention': 793120.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.q': 198152.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.q.weight': 198144.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.q.weight._data': 196608.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.q.weight._scale': 1536.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.k': 198152.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.k.weight': 198144.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.k.weight._data': 196608.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.k.weight._scale': 1536.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.v': 198152.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.v.weight': 198144.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.v.weight._data': 196608.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.v.weight._scale': 1536.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.o': 198664.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.o.weight': 198656.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.o.weight._data': 196608.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.o.weight._scale': 2048.0,\n",
       "             'encoder.block.5.layer.0.layer_norm': 2048.0,\n",
       "             'encoder.block.5.layer.0.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.5.layer.1': 1585176.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense': 1583128.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wi_0': 528392.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wi_0.weight': 528384.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wi_0.weight._data': 524288.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wi_0.weight._scale': 4096.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wi_1': 528392.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wi_1.weight': 528384.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wi_1.weight._data': 524288.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wi_1.weight._scale': 4096.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wo': 526344.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wo.weight': 526336.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wo.weight._data': 524288.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wo.weight._scale': 2048.0,\n",
       "             'encoder.block.5.layer.1.layer_norm': 2048.0,\n",
       "             'encoder.block.5.layer.1.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.6': 2380344.0,\n",
       "             'encoder.block.6.layer': 2380344.0,\n",
       "             'encoder.block.6.layer.0': 795168.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention': 793120.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.q': 198152.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.q.weight': 198144.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.q.weight._data': 196608.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.q.weight._scale': 1536.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.k': 198152.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.k.weight': 198144.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.k.weight._data': 196608.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.k.weight._scale': 1536.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.v': 198152.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.v.weight': 198144.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.v.weight._data': 196608.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.v.weight._scale': 1536.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.o': 198664.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.o.weight': 198656.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.o.weight._data': 196608.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.o.weight._scale': 2048.0,\n",
       "             'encoder.block.6.layer.0.layer_norm': 2048.0,\n",
       "             'encoder.block.6.layer.0.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.6.layer.1': 1585176.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense': 1583128.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wi_0': 528392.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wi_0.weight': 528384.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wi_0.weight._data': 524288.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wi_0.weight._scale': 4096.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wi_1': 528392.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wi_1.weight': 528384.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wi_1.weight._data': 524288.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wi_1.weight._scale': 4096.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wo': 526344.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wo.weight': 526336.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wo.weight._data': 524288.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wo.weight._scale': 2048.0,\n",
       "             'encoder.block.6.layer.1.layer_norm': 2048.0,\n",
       "             'encoder.block.6.layer.1.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.7': 2380344.0,\n",
       "             'encoder.block.7.layer': 2380344.0,\n",
       "             'encoder.block.7.layer.0': 795168.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention': 793120.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.q': 198152.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.q.weight': 198144.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.q.weight._data': 196608.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.q.weight._scale': 1536.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.k': 198152.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.k.weight': 198144.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.k.weight._data': 196608.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.k.weight._scale': 1536.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.v': 198152.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.v.weight': 198144.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.v.weight._data': 196608.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.v.weight._scale': 1536.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.o': 198664.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.o.weight': 198656.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.o.weight._data': 196608.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.o.weight._scale': 2048.0,\n",
       "             'encoder.block.7.layer.0.layer_norm': 2048.0,\n",
       "             'encoder.block.7.layer.0.layer_norm.weight': 2048.0,\n",
       "             'encoder.block.7.layer.1': 1585176.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense': 1583128.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wi_0': 528392.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wi_0.weight': 528384.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wi_0.weight._data': 524288.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wi_0.weight._scale': 4096.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wi_1': 528392.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wi_1.weight': 528384.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wi_1.weight._data': 524288.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wi_1.weight._scale': 4096.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wo': 526344.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wo.weight': 526336.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wo.weight._data': 524288.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wo.weight._scale': 2048.0,\n",
       "             'encoder.block.7.layer.1.layer_norm': 2048.0,\n",
       "             'encoder.block.7.layer.1.layer_norm.weight': 2048.0,\n",
       "             'encoder.final_layer_norm': 2048.0,\n",
       "             'encoder.final_layer_norm.weight': 2048.0,\n",
       "             'decoder': 25406912.0,\n",
       "             'decoder.block': 25404864.0,\n",
       "             'decoder.block.0': 3176280.0,\n",
       "             'decoder.block.0.layer': 3176280.0,\n",
       "             'decoder.block.0.layer.0': 795936.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention': 793888.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.q': 198152.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.q.weight': 198144.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.q.weight._data': 196608.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.q.weight._scale': 1536.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.k': 198152.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.k.weight': 198144.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.k.weight._data': 196608.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.k.weight._scale': 1536.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.v': 198152.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.v.weight': 198144.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.v.weight._data': 196608.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.v.weight._scale': 1536.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.o': 198664.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.o.weight': 198656.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.o.weight._data': 196608.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.o.weight._scale': 2048.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.relative_attention_bias': 768.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight': 768.0,\n",
       "             'decoder.block.0.layer.0.layer_norm': 2048.0,\n",
       "             'decoder.block.0.layer.0.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.0.layer.1': 795168.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention': 793120.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.q': 198152.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.q.weight': 198144.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.q.weight._data': 196608.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.q.weight._scale': 1536.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.k': 198152.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.k.weight': 198144.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.k.weight._data': 196608.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.k.weight._scale': 1536.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.v': 198152.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.v.weight': 198144.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.v.weight._data': 196608.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.v.weight._scale': 1536.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.o': 198664.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.o.weight': 198656.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.o.weight._data': 196608.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.o.weight._scale': 2048.0,\n",
       "             'decoder.block.0.layer.1.layer_norm': 2048.0,\n",
       "             'decoder.block.0.layer.1.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.0.layer.2': 1585176.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense': 1583128.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wi_0': 528392.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wi_0.weight': 528384.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wi_0.weight._data': 524288.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wi_0.weight._scale': 4096.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wi_1': 528392.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wi_1.weight': 528384.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wi_1.weight._data': 524288.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wi_1.weight._scale': 4096.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wo': 526344.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wo.weight': 526336.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wo.weight._data': 524288.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wo.weight._scale': 2048.0,\n",
       "             'decoder.block.0.layer.2.layer_norm': 2048.0,\n",
       "             'decoder.block.0.layer.2.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.1': 3175512.0,\n",
       "             'decoder.block.1.layer': 3175512.0,\n",
       "             'decoder.block.1.layer.0': 795168.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention': 793120.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.q': 198152.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.q.weight': 198144.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.q.weight._data': 196608.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.q.weight._scale': 1536.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.k': 198152.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.k.weight': 198144.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.k.weight._data': 196608.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.k.weight._scale': 1536.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.v': 198152.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.v.weight': 198144.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.v.weight._data': 196608.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.v.weight._scale': 1536.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.o': 198664.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.o.weight': 198656.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.o.weight._data': 196608.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.o.weight._scale': 2048.0,\n",
       "             'decoder.block.1.layer.0.layer_norm': 2048.0,\n",
       "             'decoder.block.1.layer.0.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.1.layer.1': 795168.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention': 793120.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.q': 198152.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.q.weight': 198144.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.q.weight._data': 196608.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.q.weight._scale': 1536.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.k': 198152.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.k.weight': 198144.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.k.weight._data': 196608.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.k.weight._scale': 1536.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.v': 198152.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.v.weight': 198144.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.v.weight._data': 196608.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.v.weight._scale': 1536.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.o': 198664.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.o.weight': 198656.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.o.weight._data': 196608.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.o.weight._scale': 2048.0,\n",
       "             'decoder.block.1.layer.1.layer_norm': 2048.0,\n",
       "             'decoder.block.1.layer.1.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.1.layer.2': 1585176.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense': 1583128.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wi_0': 528392.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wi_0.weight': 528384.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wi_0.weight._data': 524288.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wi_0.weight._scale': 4096.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wi_1': 528392.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wi_1.weight': 528384.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wi_1.weight._data': 524288.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wi_1.weight._scale': 4096.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wo': 526344.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wo.weight': 526336.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wo.weight._data': 524288.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wo.weight._scale': 2048.0,\n",
       "             'decoder.block.1.layer.2.layer_norm': 2048.0,\n",
       "             'decoder.block.1.layer.2.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.2': 3175512.0,\n",
       "             'decoder.block.2.layer': 3175512.0,\n",
       "             'decoder.block.2.layer.0': 795168.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention': 793120.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.q': 198152.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.q.weight': 198144.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.q.weight._data': 196608.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.q.weight._scale': 1536.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.k': 198152.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.k.weight': 198144.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.k.weight._data': 196608.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.k.weight._scale': 1536.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.v': 198152.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.v.weight': 198144.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.v.weight._data': 196608.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.v.weight._scale': 1536.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.o': 198664.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.o.weight': 198656.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.o.weight._data': 196608.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.o.weight._scale': 2048.0,\n",
       "             'decoder.block.2.layer.0.layer_norm': 2048.0,\n",
       "             'decoder.block.2.layer.0.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.2.layer.1': 795168.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention': 793120.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.q': 198152.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.q.weight': 198144.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.q.weight._data': 196608.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.q.weight._scale': 1536.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.k': 198152.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.k.weight': 198144.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.k.weight._data': 196608.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.k.weight._scale': 1536.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.v': 198152.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.v.weight': 198144.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.v.weight._data': 196608.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.v.weight._scale': 1536.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.o': 198664.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.o.weight': 198656.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.o.weight._data': 196608.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.o.weight._scale': 2048.0,\n",
       "             'decoder.block.2.layer.1.layer_norm': 2048.0,\n",
       "             'decoder.block.2.layer.1.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.2.layer.2': 1585176.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense': 1583128.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wi_0': 528392.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wi_0.weight': 528384.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wi_0.weight._data': 524288.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wi_0.weight._scale': 4096.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wi_1': 528392.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wi_1.weight': 528384.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wi_1.weight._data': 524288.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wi_1.weight._scale': 4096.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wo': 526344.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wo.weight': 526336.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wo.weight._data': 524288.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wo.weight._scale': 2048.0,\n",
       "             'decoder.block.2.layer.2.layer_norm': 2048.0,\n",
       "             'decoder.block.2.layer.2.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.3': 3175512.0,\n",
       "             'decoder.block.3.layer': 3175512.0,\n",
       "             'decoder.block.3.layer.0': 795168.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention': 793120.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.q': 198152.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.q.weight': 198144.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.q.weight._data': 196608.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.q.weight._scale': 1536.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.k': 198152.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.k.weight': 198144.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.k.weight._data': 196608.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.k.weight._scale': 1536.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.v': 198152.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.v.weight': 198144.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.v.weight._data': 196608.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.v.weight._scale': 1536.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.o': 198664.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.o.weight': 198656.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.o.weight._data': 196608.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.o.weight._scale': 2048.0,\n",
       "             'decoder.block.3.layer.0.layer_norm': 2048.0,\n",
       "             'decoder.block.3.layer.0.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.3.layer.1': 795168.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention': 793120.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.q': 198152.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.q.weight': 198144.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.q.weight._data': 196608.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.q.weight._scale': 1536.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.k': 198152.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.k.weight': 198144.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.k.weight._data': 196608.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.k.weight._scale': 1536.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.v': 198152.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.v.weight': 198144.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.v.weight._data': 196608.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.v.weight._scale': 1536.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.o': 198664.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.o.weight': 198656.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.o.weight._data': 196608.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.o.weight._scale': 2048.0,\n",
       "             'decoder.block.3.layer.1.layer_norm': 2048.0,\n",
       "             'decoder.block.3.layer.1.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.3.layer.2': 1585176.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense': 1583128.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wi_0': 528392.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wi_0.weight': 528384.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wi_0.weight._data': 524288.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wi_0.weight._scale': 4096.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wi_1': 528392.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wi_1.weight': 528384.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wi_1.weight._data': 524288.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wi_1.weight._scale': 4096.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wo': 526344.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wo.weight': 526336.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wo.weight._data': 524288.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wo.weight._scale': 2048.0,\n",
       "             'decoder.block.3.layer.2.layer_norm': 2048.0,\n",
       "             'decoder.block.3.layer.2.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.4': 3175512.0,\n",
       "             'decoder.block.4.layer': 3175512.0,\n",
       "             'decoder.block.4.layer.0': 795168.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention': 793120.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.q': 198152.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.q.weight': 198144.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.q.weight._data': 196608.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.q.weight._scale': 1536.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.k': 198152.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.k.weight': 198144.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.k.weight._data': 196608.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.k.weight._scale': 1536.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.v': 198152.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.v.weight': 198144.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.v.weight._data': 196608.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.v.weight._scale': 1536.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.o': 198664.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.o.weight': 198656.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.o.weight._data': 196608.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.o.weight._scale': 2048.0,\n",
       "             'decoder.block.4.layer.0.layer_norm': 2048.0,\n",
       "             'decoder.block.4.layer.0.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.4.layer.1': 795168.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention': 793120.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.q': 198152.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.q.weight': 198144.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.q.weight._data': 196608.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.q.weight._scale': 1536.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.k': 198152.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.k.weight': 198144.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.k.weight._data': 196608.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.k.weight._scale': 1536.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.v': 198152.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.v.weight': 198144.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.v.weight._data': 196608.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.v.weight._scale': 1536.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.o': 198664.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.o.weight': 198656.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.o.weight._data': 196608.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.o.weight._scale': 2048.0,\n",
       "             'decoder.block.4.layer.1.layer_norm': 2048.0,\n",
       "             'decoder.block.4.layer.1.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.4.layer.2': 1585176.0,\n",
       "             'decoder.block.4.layer.2.DenseReluDense': 1583128.0,\n",
       "             'decoder.block.4.layer.2.DenseReluDense.wi_0': 528392.0,\n",
       "             'decoder.block.4.layer.2.DenseReluDense.wi_0.weight': 528384.0,\n",
       "             'decoder.block.4.layer.2.DenseReluDense.wi_0.weight._data': 524288.0,\n",
       "             'decoder.block.4.layer.2.DenseReluDense.wi_0.weight._scale': 4096.0,\n",
       "             'decoder.block.4.layer.2.DenseReluDense.wi_1': 528392.0,\n",
       "             'decoder.block.4.layer.2.DenseReluDense.wi_1.weight': 528384.0,\n",
       "             'decoder.block.4.layer.2.DenseReluDense.wi_1.weight._data': 524288.0,\n",
       "             'decoder.block.4.layer.2.DenseReluDense.wi_1.weight._scale': 4096.0,\n",
       "             'decoder.block.4.layer.2.DenseReluDense.wo': 526344.0,\n",
       "             'decoder.block.4.layer.2.DenseReluDense.wo.weight': 526336.0,\n",
       "             'decoder.block.4.layer.2.DenseReluDense.wo.weight._data': 524288.0,\n",
       "             'decoder.block.4.layer.2.DenseReluDense.wo.weight._scale': 2048.0,\n",
       "             'decoder.block.4.layer.2.layer_norm': 2048.0,\n",
       "             'decoder.block.4.layer.2.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.5': 3175512.0,\n",
       "             'decoder.block.5.layer': 3175512.0,\n",
       "             'decoder.block.5.layer.0': 795168.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention': 793120.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.q': 198152.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.q.weight': 198144.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.q.weight._data': 196608.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.q.weight._scale': 1536.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.k': 198152.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.k.weight': 198144.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.k.weight._data': 196608.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.k.weight._scale': 1536.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.v': 198152.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.v.weight': 198144.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.v.weight._data': 196608.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.v.weight._scale': 1536.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.o': 198664.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.o.weight': 198656.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.o.weight._data': 196608.0,\n",
       "             'decoder.block.5.layer.0.SelfAttention.o.weight._scale': 2048.0,\n",
       "             'decoder.block.5.layer.0.layer_norm': 2048.0,\n",
       "             'decoder.block.5.layer.0.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.5.layer.1': 795168.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention': 793120.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.q': 198152.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.q.weight': 198144.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.q.weight._data': 196608.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.q.weight._scale': 1536.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.k': 198152.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.k.weight': 198144.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.k.weight._data': 196608.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.k.weight._scale': 1536.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.v': 198152.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.v.weight': 198144.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.v.weight._data': 196608.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.v.weight._scale': 1536.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.o': 198664.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.o.weight': 198656.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.o.weight._data': 196608.0,\n",
       "             'decoder.block.5.layer.1.EncDecAttention.o.weight._scale': 2048.0,\n",
       "             'decoder.block.5.layer.1.layer_norm': 2048.0,\n",
       "             'decoder.block.5.layer.1.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.5.layer.2': 1585176.0,\n",
       "             'decoder.block.5.layer.2.DenseReluDense': 1583128.0,\n",
       "             'decoder.block.5.layer.2.DenseReluDense.wi_0': 528392.0,\n",
       "             'decoder.block.5.layer.2.DenseReluDense.wi_0.weight': 528384.0,\n",
       "             'decoder.block.5.layer.2.DenseReluDense.wi_0.weight._data': 524288.0,\n",
       "             'decoder.block.5.layer.2.DenseReluDense.wi_0.weight._scale': 4096.0,\n",
       "             'decoder.block.5.layer.2.DenseReluDense.wi_1': 528392.0,\n",
       "             'decoder.block.5.layer.2.DenseReluDense.wi_1.weight': 528384.0,\n",
       "             'decoder.block.5.layer.2.DenseReluDense.wi_1.weight._data': 524288.0,\n",
       "             'decoder.block.5.layer.2.DenseReluDense.wi_1.weight._scale': 4096.0,\n",
       "             'decoder.block.5.layer.2.DenseReluDense.wo': 526344.0,\n",
       "             'decoder.block.5.layer.2.DenseReluDense.wo.weight': 526336.0,\n",
       "             'decoder.block.5.layer.2.DenseReluDense.wo.weight._data': 524288.0,\n",
       "             'decoder.block.5.layer.2.DenseReluDense.wo.weight._scale': 2048.0,\n",
       "             'decoder.block.5.layer.2.layer_norm': 2048.0,\n",
       "             'decoder.block.5.layer.2.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.6': 3175512.0,\n",
       "             'decoder.block.6.layer': 3175512.0,\n",
       "             'decoder.block.6.layer.0': 795168.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention': 793120.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.q': 198152.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.q.weight': 198144.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.q.weight._data': 196608.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.q.weight._scale': 1536.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.k': 198152.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.k.weight': 198144.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.k.weight._data': 196608.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.k.weight._scale': 1536.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.v': 198152.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.v.weight': 198144.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.v.weight._data': 196608.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.v.weight._scale': 1536.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.o': 198664.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.o.weight': 198656.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.o.weight._data': 196608.0,\n",
       "             'decoder.block.6.layer.0.SelfAttention.o.weight._scale': 2048.0,\n",
       "             'decoder.block.6.layer.0.layer_norm': 2048.0,\n",
       "             'decoder.block.6.layer.0.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.6.layer.1': 795168.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention': 793120.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.q': 198152.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.q.weight': 198144.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.q.weight._data': 196608.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.q.weight._scale': 1536.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.k': 198152.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.k.weight': 198144.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.k.weight._data': 196608.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.k.weight._scale': 1536.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.v': 198152.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.v.weight': 198144.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.v.weight._data': 196608.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.v.weight._scale': 1536.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.o': 198664.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.o.weight': 198656.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.o.weight._data': 196608.0,\n",
       "             'decoder.block.6.layer.1.EncDecAttention.o.weight._scale': 2048.0,\n",
       "             'decoder.block.6.layer.1.layer_norm': 2048.0,\n",
       "             'decoder.block.6.layer.1.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.6.layer.2': 1585176.0,\n",
       "             'decoder.block.6.layer.2.DenseReluDense': 1583128.0,\n",
       "             'decoder.block.6.layer.2.DenseReluDense.wi_0': 528392.0,\n",
       "             'decoder.block.6.layer.2.DenseReluDense.wi_0.weight': 528384.0,\n",
       "             'decoder.block.6.layer.2.DenseReluDense.wi_0.weight._data': 524288.0,\n",
       "             'decoder.block.6.layer.2.DenseReluDense.wi_0.weight._scale': 4096.0,\n",
       "             'decoder.block.6.layer.2.DenseReluDense.wi_1': 528392.0,\n",
       "             'decoder.block.6.layer.2.DenseReluDense.wi_1.weight': 528384.0,\n",
       "             'decoder.block.6.layer.2.DenseReluDense.wi_1.weight._data': 524288.0,\n",
       "             'decoder.block.6.layer.2.DenseReluDense.wi_1.weight._scale': 4096.0,\n",
       "             'decoder.block.6.layer.2.DenseReluDense.wo': 526344.0,\n",
       "             'decoder.block.6.layer.2.DenseReluDense.wo.weight': 526336.0,\n",
       "             'decoder.block.6.layer.2.DenseReluDense.wo.weight._data': 524288.0,\n",
       "             'decoder.block.6.layer.2.DenseReluDense.wo.weight._scale': 2048.0,\n",
       "             'decoder.block.6.layer.2.layer_norm': 2048.0,\n",
       "             'decoder.block.6.layer.2.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.7': 3175512.0,\n",
       "             'decoder.block.7.layer': 3175512.0,\n",
       "             'decoder.block.7.layer.0': 795168.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention': 793120.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.q': 198152.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.q.weight': 198144.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.q.weight._data': 196608.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.q.weight._scale': 1536.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.k': 198152.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.k.weight': 198144.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.k.weight._data': 196608.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.k.weight._scale': 1536.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.v': 198152.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.v.weight': 198144.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.v.weight._data': 196608.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.v.weight._scale': 1536.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.o': 198664.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.o.weight': 198656.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.o.weight._data': 196608.0,\n",
       "             'decoder.block.7.layer.0.SelfAttention.o.weight._scale': 2048.0,\n",
       "             'decoder.block.7.layer.0.layer_norm': 2048.0,\n",
       "             'decoder.block.7.layer.0.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.7.layer.1': 795168.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention': 793120.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.q': 198152.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.q.weight': 198144.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.q.weight._data': 196608.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.q.weight._scale': 1536.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.k': 198152.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.k.weight': 198144.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.k.weight._data': 196608.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.k.weight._scale': 1536.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.v': 198152.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.v.weight': 198144.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.v.weight._data': 196608.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.v.weight._scale': 1536.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.o': 198664.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.o.weight': 198656.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.o.weight._data': 196608.0,\n",
       "             'decoder.block.7.layer.1.EncDecAttention.o.weight._scale': 2048.0,\n",
       "             'decoder.block.7.layer.1.layer_norm': 2048.0,\n",
       "             'decoder.block.7.layer.1.layer_norm.weight': 2048.0,\n",
       "             'decoder.block.7.layer.2': 1585176.0,\n",
       "             'decoder.block.7.layer.2.DenseReluDense': 1583128.0,\n",
       "             'decoder.block.7.layer.2.DenseReluDense.wi_0': 528392.0,\n",
       "             'decoder.block.7.layer.2.DenseReluDense.wi_0.weight': 528384.0,\n",
       "             'decoder.block.7.layer.2.DenseReluDense.wi_0.weight._data': 524288.0,\n",
       "             'decoder.block.7.layer.2.DenseReluDense.wi_0.weight._scale': 4096.0,\n",
       "             'decoder.block.7.layer.2.DenseReluDense.wi_1': 528392.0,\n",
       "             'decoder.block.7.layer.2.DenseReluDense.wi_1.weight': 528384.0,\n",
       "             'decoder.block.7.layer.2.DenseReluDense.wi_1.weight._data': 524288.0,\n",
       "             'decoder.block.7.layer.2.DenseReluDense.wi_1.weight._scale': 4096.0,\n",
       "             'decoder.block.7.layer.2.DenseReluDense.wo': 526344.0,\n",
       "             'decoder.block.7.layer.2.DenseReluDense.wo.weight': 526336.0,\n",
       "             'decoder.block.7.layer.2.DenseReluDense.wo.weight._data': 524288.0,\n",
       "             'decoder.block.7.layer.2.DenseReluDense.wo.weight._scale': 2048.0,\n",
       "             'decoder.block.7.layer.2.layer_norm': 2048.0,\n",
       "             'decoder.block.7.layer.2.layer_norm.weight': 2048.0,\n",
       "             'decoder.final_layer_norm': 2048.0,\n",
       "             'decoder.final_layer_norm.weight': 2048.0,\n",
       "             'lm_head': 16578056.0,\n",
       "             'lm_head.weight': 16578048.0,\n",
       "             'lm_head.weight._data': 16449536.0,\n",
       "             'lm_head.weight._scale': 128512.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.q.input_scale': 4.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.q.output_scale': 4.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.k.input_scale': 4.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.k.output_scale': 4.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.v.input_scale': 4.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.v.output_scale': 4.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.o.input_scale': 4.0,\n",
       "             'encoder.block.0.layer.0.SelfAttention.o.output_scale': 4.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wi_0.input_scale': 4.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wi_0.output_scale': 4.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wi_1.input_scale': 4.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wi_1.output_scale': 4.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wo.input_scale': 4.0,\n",
       "             'encoder.block.0.layer.1.DenseReluDense.wo.output_scale': 4.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.q.input_scale': 4.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.q.output_scale': 4.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.k.input_scale': 4.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.k.output_scale': 4.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.v.input_scale': 4.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.v.output_scale': 4.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.o.input_scale': 4.0,\n",
       "             'encoder.block.1.layer.0.SelfAttention.o.output_scale': 4.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wi_0.input_scale': 4.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wi_0.output_scale': 4.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wi_1.input_scale': 4.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wi_1.output_scale': 4.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wo.input_scale': 4.0,\n",
       "             'encoder.block.1.layer.1.DenseReluDense.wo.output_scale': 4.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.q.input_scale': 4.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.q.output_scale': 4.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.k.input_scale': 4.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.k.output_scale': 4.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.v.input_scale': 4.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.v.output_scale': 4.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.o.input_scale': 4.0,\n",
       "             'encoder.block.2.layer.0.SelfAttention.o.output_scale': 4.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wi_0.input_scale': 4.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wi_0.output_scale': 4.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wi_1.input_scale': 4.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wi_1.output_scale': 4.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wo.input_scale': 4.0,\n",
       "             'encoder.block.2.layer.1.DenseReluDense.wo.output_scale': 4.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.q.input_scale': 4.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.q.output_scale': 4.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.k.input_scale': 4.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.k.output_scale': 4.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.v.input_scale': 4.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.v.output_scale': 4.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.o.input_scale': 4.0,\n",
       "             'encoder.block.3.layer.0.SelfAttention.o.output_scale': 4.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wi_0.input_scale': 4.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wi_0.output_scale': 4.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wi_1.input_scale': 4.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wi_1.output_scale': 4.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wo.input_scale': 4.0,\n",
       "             'encoder.block.3.layer.1.DenseReluDense.wo.output_scale': 4.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.q.input_scale': 4.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.q.output_scale': 4.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.k.input_scale': 4.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.k.output_scale': 4.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.v.input_scale': 4.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.v.output_scale': 4.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.o.input_scale': 4.0,\n",
       "             'encoder.block.4.layer.0.SelfAttention.o.output_scale': 4.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wi_0.input_scale': 4.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wi_0.output_scale': 4.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wi_1.input_scale': 4.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wi_1.output_scale': 4.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wo.input_scale': 4.0,\n",
       "             'encoder.block.4.layer.1.DenseReluDense.wo.output_scale': 4.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.q.input_scale': 4.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.q.output_scale': 4.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.k.input_scale': 4.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.k.output_scale': 4.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.v.input_scale': 4.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.v.output_scale': 4.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.o.input_scale': 4.0,\n",
       "             'encoder.block.5.layer.0.SelfAttention.o.output_scale': 4.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wi_0.input_scale': 4.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wi_0.output_scale': 4.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wi_1.input_scale': 4.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wi_1.output_scale': 4.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wo.input_scale': 4.0,\n",
       "             'encoder.block.5.layer.1.DenseReluDense.wo.output_scale': 4.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.q.input_scale': 4.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.q.output_scale': 4.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.k.input_scale': 4.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.k.output_scale': 4.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.v.input_scale': 4.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.v.output_scale': 4.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.o.input_scale': 4.0,\n",
       "             'encoder.block.6.layer.0.SelfAttention.o.output_scale': 4.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wi_0.input_scale': 4.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wi_0.output_scale': 4.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wi_1.input_scale': 4.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wi_1.output_scale': 4.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wo.input_scale': 4.0,\n",
       "             'encoder.block.6.layer.1.DenseReluDense.wo.output_scale': 4.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.q.input_scale': 4.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.q.output_scale': 4.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.k.input_scale': 4.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.k.output_scale': 4.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.v.input_scale': 4.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.v.output_scale': 4.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.o.input_scale': 4.0,\n",
       "             'encoder.block.7.layer.0.SelfAttention.o.output_scale': 4.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wi_0.input_scale': 4.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wi_0.output_scale': 4.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wi_1.input_scale': 4.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wi_1.output_scale': 4.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wo.input_scale': 4.0,\n",
       "             'encoder.block.7.layer.1.DenseReluDense.wo.output_scale': 4.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.q.input_scale': 4.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.q.output_scale': 4.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.k.input_scale': 4.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.k.output_scale': 4.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.v.input_scale': 4.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.v.output_scale': 4.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.o.input_scale': 4.0,\n",
       "             'decoder.block.0.layer.0.SelfAttention.o.output_scale': 4.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.q.input_scale': 4.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.q.output_scale': 4.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.k.input_scale': 4.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.k.output_scale': 4.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.v.input_scale': 4.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.v.output_scale': 4.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.o.input_scale': 4.0,\n",
       "             'decoder.block.0.layer.1.EncDecAttention.o.output_scale': 4.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wi_0.input_scale': 4.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wi_0.output_scale': 4.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wi_1.input_scale': 4.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wi_1.output_scale': 4.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wo.input_scale': 4.0,\n",
       "             'decoder.block.0.layer.2.DenseReluDense.wo.output_scale': 4.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.q.input_scale': 4.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.q.output_scale': 4.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.k.input_scale': 4.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.k.output_scale': 4.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.v.input_scale': 4.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.v.output_scale': 4.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.o.input_scale': 4.0,\n",
       "             'decoder.block.1.layer.0.SelfAttention.o.output_scale': 4.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.q.input_scale': 4.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.q.output_scale': 4.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.k.input_scale': 4.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.k.output_scale': 4.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.v.input_scale': 4.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.v.output_scale': 4.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.o.input_scale': 4.0,\n",
       "             'decoder.block.1.layer.1.EncDecAttention.o.output_scale': 4.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wi_0.input_scale': 4.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wi_0.output_scale': 4.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wi_1.input_scale': 4.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wi_1.output_scale': 4.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wo.input_scale': 4.0,\n",
       "             'decoder.block.1.layer.2.DenseReluDense.wo.output_scale': 4.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.q.input_scale': 4.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.q.output_scale': 4.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.k.input_scale': 4.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.k.output_scale': 4.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.v.input_scale': 4.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.v.output_scale': 4.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.o.input_scale': 4.0,\n",
       "             'decoder.block.2.layer.0.SelfAttention.o.output_scale': 4.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.q.input_scale': 4.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.q.output_scale': 4.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.k.input_scale': 4.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.k.output_scale': 4.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.v.input_scale': 4.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.v.output_scale': 4.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.o.input_scale': 4.0,\n",
       "             'decoder.block.2.layer.1.EncDecAttention.o.output_scale': 4.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wi_0.input_scale': 4.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wi_0.output_scale': 4.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wi_1.input_scale': 4.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wi_1.output_scale': 4.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wo.input_scale': 4.0,\n",
       "             'decoder.block.2.layer.2.DenseReluDense.wo.output_scale': 4.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.q.input_scale': 4.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.q.output_scale': 4.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.k.input_scale': 4.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.k.output_scale': 4.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.v.input_scale': 4.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.v.output_scale': 4.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.o.input_scale': 4.0,\n",
       "             'decoder.block.3.layer.0.SelfAttention.o.output_scale': 4.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.q.input_scale': 4.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.q.output_scale': 4.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.k.input_scale': 4.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.k.output_scale': 4.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.v.input_scale': 4.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.v.output_scale': 4.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.o.input_scale': 4.0,\n",
       "             'decoder.block.3.layer.1.EncDecAttention.o.output_scale': 4.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wi_0.input_scale': 4.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wi_0.output_scale': 4.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wi_1.input_scale': 4.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wi_1.output_scale': 4.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wo.input_scale': 4.0,\n",
       "             'decoder.block.3.layer.2.DenseReluDense.wo.output_scale': 4.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.q.input_scale': 4.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.q.output_scale': 4.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.k.input_scale': 4.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.k.output_scale': 4.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.v.input_scale': 4.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.v.output_scale': 4.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.o.input_scale': 4.0,\n",
       "             'decoder.block.4.layer.0.SelfAttention.o.output_scale': 4.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.q.input_scale': 4.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.q.output_scale': 4.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.k.input_scale': 4.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.k.output_scale': 4.0,\n",
       "             'decoder.block.4.layer.1.EncDecAttention.v.input_scale': 4.0,\n",
       "             ...})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_sizes = compute_model_sizes(model=model)\n",
    "module_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model size is 0.12682868 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"The model size is {module_sizes[''] * 1e-9} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying running inference on the quantized model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> annie scott</s>\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Hello, my name is \"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: Quantizing the model used in the lecture video will not work due to classroom hardware limitations.\n",
    "- Here is the code that Marc, the instructor is walking through.  \n",
    "- It will likely run on your local computer if you have 8GB of memory, which is usually the minimum for personal computers.\n",
    "  - To run locally, you can download the notebook and the helper.py file by clicking on the \"Jupyter icon\" at the top of the notebook and navigating the file directory of this classroom.  Also download the requirements.txt to install all the required libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Quantization\n",
    "- Load [EleutherAI/pythia-410m](https://huggingface.co/EleutherAI/pythia-410m) model and tokenizer.\n",
    "\n",
    "```Python\n",
    "from transformers import AutoModelForCausalLM\n",
    "model_name = \"EleutherAI/pythia-410m\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             low_cpu_mem_usage=True)\n",
    "print(model.gpt_neox)\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a start of a (`text`) sentence which you'd like the model to complete.\n",
    "```Python\n",
    "text = \"Hello my name is\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "outputs\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute the model's size using the helper function, `compute_module_sizes`.\n",
    "```Python\n",
    "from helper import compute_module_sizes\n",
    "module_sizes = compute_module_sizes(model)\n",
    "print(f\"The model size is {module_sizes[''] * 1e-9} GB\")\n",
    "print(model.gpt_neox.layers[0].attention.dense.weight)\n",
    "```\n",
    "**Note:** The weights are in `fp32`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-bit Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "from quanto import quantize, freeze\n",
    "import torch\n",
    "\n",
    "quantize(model, weights=torch.int8, activations=None)\n",
    "# after performing quantization\n",
    "print(model.gpt_neox)\n",
    "print(model.gpt_neox.layers[0].attention.dense.weight)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The \"freeze\" function requires more memory than is available in this classroom.\n",
    "- This code will run on a machine that has 8GB of memory, and so it will likely work if you run this code on your local machine.\n",
    "\n",
    "```Python\n",
    "# freeze the model\n",
    "freeze(model)\n",
    "print(model.gpt_neox.layers[0].attention.dense.weight)\n",
    "\n",
    "# get model size after quantization\n",
    "module_sizes = compute_module_sizes(model)\n",
    "print(f\"The model size is {module_sizes[''] * 1e-9} GB\")\n",
    "\n",
    "# run inference after quantizing the model\n",
    "outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing \"linear quantization\" to \"downcasting\"\n",
    "\n",
    "To recap the difference between the \"linear quantization\" method in this lesson with the \"downcasting\" method in the previous lesson:\n",
    "\n",
    "- When downcasting a model, you convert the model's parameters to a more compact data type (bfloat16).  During inference, the model performs its calculations in this data type, and its activations are in this data type.  Downcasting may work with the bfloat16 data type, but the model performance will likely degrade with any smaller data type, and won't work if you convert to an integer data type (like the int8 in this lesson).\n",
    "\n",
    "\n",
    "- In this lesson, you used another quantization method, \"linear quantization\", which enables the quantized model to maintain performance much closer to the original model by converting from the compressed data type back to the original FP32 data type during inference. So when the model makes a prediction, it is performing the matrix multiplications in FP32, and the activations are in FP32.  This enables you to quantize the model in data types smaller than bfloat16, such as int8, in this example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_quantization_fundamentals_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
